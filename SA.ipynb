{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_groq import ChatGroq\n",
    "import streamlit as st\n",
    "from langchain_core.prompts import ChatPromptTemplate \n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "import pdfplumber\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llama = ChatGroq(\n",
    "    model=\"LLaMA3-70B-8192\",\n",
    "    groq_api_key='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',\n",
    "    temperature=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title\n",
    "st.title(\"AI EXAM PREPPER by PARTH &mdash;:books::magic_wand:\")\n",
    "\n",
    "# Pages defined Home, Question, Answer, Concept-Learning Plan\n",
    "pages = {\n",
    "    \"Home\": [\n",
    "        st.Page(\"Home.py\", title=\"Welcome!\"),\n",
    "    ],\n",
    "    \"Question\": [\n",
    "        st.Page(\"Que.py\", title=\"Upload your PYQ papers.\"),\n",
    "    ],\n",
    "    \"Answer\": [\n",
    "        st.Page(\"Answer.py\", title=\"Enter the question text file.\"),\n",
    "    ],\n",
    "    \"Concept-Learning Plan\": [\n",
    "        st.Page(\"PL.py\", title=\"Enter the question text file.\"),\n",
    "    ],\n",
    "}\n",
    "\n",
    "#Clear history button\n",
    "st.sidebar.markdown(\"\"\"\n",
    "                    **This button will clear the response history.** &mdash; :point_down:\\n \n",
    "                    Recommended if you are switching pages.\n",
    "                    \"\"\")\n",
    "if st.sidebar.button(\"Clear History\"):\n",
    "    st.session_state.clear()\n",
    "\n",
    "# Navigation page execution\n",
    "pg = st.navigation(pages)\n",
    "pg.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Introduction Text\n",
    "st.markdown(\"\"\"\n",
    "### Hello students! Hope you find this app when your exam is near.\\n\n",
    "This app will make your exam preparations smooth as butter!\\n\n",
    "        Functionalities; this app provides:\\n\n",
    "            1. Question\n",
    "            2. Answer\n",
    "            3. Concept-Learning Plan\n",
    "\"\"\")\n",
    "\n",
    "# How to use section\n",
    "st.markdown(\"**How to use?**\")\n",
    "\n",
    "with st.expander(\"Instructions to follow...\"):\n",
    "    st.markdown(\"\"\"\n",
    "Open the **Question** page -> Upload pyq papers (only in pdf format) -> Download the ***Question_response*** text file.\\n \n",
    "You can you this file for both Answer page and Concept-Learning Plan for getting responses.\\n\n",
    "                \"\"\")\n",
    "    \n",
    "\n",
    "# Description\n",
    "st.markdown(\"**Description about app's functions**\")\n",
    "\n",
    "with st.expander(\"About Question...\"):\n",
    "    st.markdown(\"\"\"\n",
    "    **Question** is a place where you upload your Past Year Question papers and get your imp questions in seconds.\\n\n",
    "    Input: Question papers(one or more) **Format:** PDF\\n\n",
    "    Task: It will generate you a list of questions which are repeated and catagorize it on concept base.\\n\n",
    "    Output: List of imp questions. Also, you can download it as a file.\n",
    "    \"\"\")\n",
    "\n",
    "with st.expander(\"About Answer...\"):\n",
    "    st.markdown(\"\"\"\n",
    "In **Answer** page, you will get brief and informative answer for any questions provided. \\n\n",
    "Input: The ***Question_response*** text file from the **Question** page.\\n\n",
    "Task: Generation of answers with conceptual understanding.\\n\n",
    "Output: Answer text file to download.                          \n",
    "\"\"\")\n",
    "    \n",
    "with st.expander(\"About Concept-Learning Plan...\"):\n",
    "    st.markdown(\"\"\"\n",
    "In **Concept-Learning Plan** page, you will get a guided study plan to kickstart your studying.\\n\n",
    "Input: The ***Question_response*** text file from the **Question** page.\\n\n",
    "Task: Generation of a Study plan according to your imp concepts covered in the exam with a flow chart to visualize it better.\\n\n",
    "Output: Plan text file to download.                                               \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quesion Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setting up chains\n",
    "\n",
    "qchain= ( ChatPromptTemplate.from_template(\"Create and Provide a list of the repeated questions 'or' similar conceptual questions with their concept from the {base_response}. Also, If any questions are repeated then state their repetitions.\")\n",
    "                      | llama\n",
    "                      | StrOutputParser()\n",
    "                      #| {\"q_response\": RunnablePassthrough()}\n",
    "                      \n",
    "            )\n",
    "basechain = ( ChatPromptTemplate.from_template(\"you are a expert analyst. Your task is to Analyzize these question papers {res} and find all the questions from each question paper according to their concept.\")\n",
    "                      | llama\n",
    "                      | StrOutputParser()\n",
    "                      |{\"base_response\": RunnablePassthrough()}\n",
    "                      \n",
    "            )\n",
    "\n",
    "mainchainq = (\n",
    "     basechain\n",
    "     | qchain\n",
    ")\n",
    "\n",
    "# Load Groq compiled LLaMA model (replace with your actual model path)\n",
    "@st.cache_resource\n",
    "\n",
    "\n",
    "# Function to download response\n",
    "def download_response_as_pdf(bot_response):\n",
    "    st.download_button(\n",
    "        label=\"Download as file\",\n",
    "        data=bot_response,\n",
    "        file_name=\"Question_response.txt\"\n",
    "    )\n",
    "     \n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "# Getting user input\n",
    "uploaded_files = st.file_uploader(\n",
    "        \"Upload your PYQ papers below. (Only .pdf is allowed)\", accept_multiple_files=True\n",
    "    )\n",
    "\n",
    "# Function to extract text from files\n",
    "def extract():\n",
    "    \n",
    "        extracted_text = []\n",
    "        for file in uploaded_files:\n",
    "            with pdfplumber.open(file) as pdf:\n",
    "                for page in pdf.pages:\n",
    "                    extracted_text.append(page.extract_text())\n",
    "                   \n",
    "        return extracted_text\n",
    "res= extract()\n",
    "\n",
    "# Submit button action\n",
    "if st.button(\"Submit\"):\n",
    "     message = st.chat_message(\"assistant\")\n",
    "     bot_response = mainchainq.invoke(res)\n",
    "     st.session_state.messages.append({\"role\": \"assistant\", \"content\": bot_response})\n",
    "     download_response_as_pdf(bot_response)\n",
    "\n",
    "# # Display chat history\n",
    "for message in st.session_state.messages:\n",
    "    if message[\"role\"] == \"assistant\":\n",
    "        st.write(f\"bot: {message['content']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setting up chains\n",
    "achain= ( ChatPromptTemplate.from_template(\"You are an intelligent ai made for assisting students for completing their assingnments. Generate informative answers  of minimum 700 words for every question in this assignment {que}\")\n",
    "                      | llama\n",
    "                      | StrOutputParser()\n",
    "            )\n",
    "basechain = ( ChatPromptTemplate.from_template(\"you are a expert analyst. Your task is to Analyzize these questions {que} with their concepts.\")\n",
    "                      | llama\n",
    "                      | StrOutputParser()\n",
    "                      |{\"base_response\": RunnablePassthrough()}\n",
    ")\n",
    "anschain= (\n",
    "    basechain\n",
    "    | achain\n",
    ")\n",
    "\n",
    "# Getting user input\n",
    "uploaded_files = st.file_uploader(\n",
    "        \"Note: Only upload the Question_response.txt file\", accept_multiple_files=True\n",
    "    )\n",
    "\n",
    "# Function to extract text from files\n",
    "def questions():\n",
    "    decoded_text = []\n",
    "    for file in uploaded_files:\n",
    "        file_bytes = file.read()\n",
    "        decoded_text = file_bytes.decode(\"utf-8\")\n",
    "    return decoded_text\n",
    "que = questions()\n",
    "\n",
    "# Function to download response\n",
    "def download_response_as_pdf(bot_response):\n",
    "    st.download_button(\n",
    "        label=\"Download as file\",\n",
    "        data=bot_response,\n",
    "        file_name=\"Ans_response.txt\"\n",
    "    )\n",
    "\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "# Submit button action\n",
    "if st.button(\"Submit\"):\n",
    "     message = st.chat_message(\"assistant\")\n",
    "     bot_response = achain.invoke(que)\n",
    "     st.session_state.messages.append({\"role\": \"assistant\", \"content\": bot_response})\n",
    "     download_response_as_pdf(bot_response)\n",
    "\n",
    "for message in st.session_state.messages:\n",
    "    if message[\"role\"] == \"assistant\":\n",
    "        st.write(f\"bot: {message['content']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concept-Learning Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setting up chains\n",
    "cchain= ( ChatPromptTemplate.from_template(\"you are a expert analyst. your task is to Create a hierarchal plan for studying these concepts {concepts} and represent it with flow chart. Also, explain the your created plan. Guide and encourage students to follow your plan.\")\n",
    "                      | llama\n",
    "                      | StrOutputParser()\n",
    "            )\n",
    "basechain = ( ChatPromptTemplate.from_template(\"you are a expert analyst. Your task is to Analyzize the given text {txt} and find out the concepts covered in it.\")\n",
    "                      | llama\n",
    "                      | StrOutputParser()\n",
    "                      |{\"concepts\": RunnablePassthrough()}\n",
    ")\n",
    "conchain= (\n",
    "    basechain\n",
    "    | cchain\n",
    ")\n",
    "\n",
    "# Getting user input\n",
    "uploaded_files = st.file_uploader(\n",
    "        \"Note: Only upload the Question_response.txt file\", accept_multiple_files=True\n",
    "    )\n",
    "\n",
    "# Function to extract text from files\n",
    "def concept():\n",
    "    decoded_text = []\n",
    "    for file in uploaded_files:\n",
    "        file_bytes = file.read()\n",
    "        decoded_text = file_bytes.decode(\"utf-8\")\n",
    "    return decoded_text\n",
    "txt = concept()\n",
    "\n",
    "# Function to download response\n",
    "def download_response_as_pdf(bot_response):\n",
    "    st.download_button(\n",
    "        label=\"Download as file\",\n",
    "        data=bot_response,\n",
    "        file_name=\"Plan_response.txt\",\n",
    "        #mime=\"application/pdf\"\n",
    "    )\n",
    "\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "if st.button(\"Submit\"):\n",
    "     message = st.chat_message(\"assistant\")\n",
    "     bot_response = conchain.invoke(txt)\n",
    "     st.session_state.messages.append({\"role\": \"assistant\", \"content\": bot_response})\n",
    "     download_response_as_pdf(bot_response)\n",
    "\n",
    "for message in st.session_state.messages:\n",
    "    if message[\"role\"] == \"assistant\":\n",
    "        st.write(f\"bot: {message['content']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
